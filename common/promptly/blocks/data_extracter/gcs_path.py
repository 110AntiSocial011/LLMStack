# AUTOGENERATED
from datetime import datetime
from typing import Dict
from typing import Generator
from typing import Generic
from typing import Optional

from google.cloud import storage

from common.promptly.core.base import BaseConfiguration
from common.promptly.core.base import BaseConfigurationType
from common.promptly.core.base import BaseInput
from common.promptly.core.base import BaseInputType
from common.promptly.core.base import BaseOutput
from common.promptly.core.base import BaseOutputType
from common.promptly.core.base import BaseProcessor
from common.promptly.core.base import Schema


class GCSPathDataExtractorBlockInput(BaseInput):
    """ GCS file path to extract data from"""
    path: str
    bucket: str


class GCSResponseMetadata(Schema):
    generation: str
    metageneration: str
    content_type: str
    time_created: datetime
    updated: datetime
    storage_class: str
    md5_hash: str
    crc32c: str
    size: int


class GCSFileData(Schema):
    metadata: GCSResponseMetadata
    content: bytes
    path: str


class GCSPathDataExtractorBlockOutput(BaseOutput):
    result: GCSFileData


class GCSPathDataExtractorBlockConfiguration(BaseConfiguration):
    project_id: Optional[str] = None
    credentials: Optional[Dict] = None


class GCSPathDataExtractorBlock(BaseProcessor[GCSPathDataExtractorBlockInput, GCSPathDataExtractorBlockOutput, GCSPathDataExtractorBlockConfiguration],  Generic[BaseInputType, BaseOutputType, BaseConfigurationType]):
    def __init__(self, configuration: dict):
        super().__init__(configuration)
        self._gcs_client = storage.Client(**configuration)

    def _get_metadata(self, gcs_blob):
        return GCSResponseMetadata(
            generation=gcs_blob.generation,
            metageneration=gcs_blob.metageneration,
            content_type=gcs_blob.content_type,
            time_created=gcs_blob.time_created,
            updated=gcs_blob.updated,
            storage_class=gcs_blob.storage_class,
            md5_hash=gcs_blob.md5_hash,
            crc32c=gcs_blob.crc32c,
            size=gcs_blob.size,
        )

    def _get_file_content(self, gcs_blob):
        content = gcs_blob.download_as_bytes()
        if type(content) == bytes:
            return content
        elif type(content) == str:
            return content.encode('utf-8')
        else:
            raise Exception('Unknown content type')

    def _process(self, input: GCSPathDataExtractorBlockInput, configuration: GCSPathDataExtractorBlockConfiguration) -> GCSPathDataExtractorBlockOutput:
        bucket = self._gcs_client.get_bucket(input.bucket)
        blob = bucket.get_blob(input.path)

        return GCSPathDataExtractorBlockOutput(
            result=GCSFileData(
                metadata=self._get_metadata(blob),
                content=self._get_file_content(
                    blob,
                ),
                path=f'{input.bucket}/{input.path}',
            ),
        )

    def _process_iter(self, input: GCSPathDataExtractorBlockInput, configuration: GCSPathDataExtractorBlockConfiguration) -> Generator[GCSPathDataExtractorBlockOutput, None, None]:
        # Read file byte by byte
        bucket = self._gcs_client.get_bucket(input.bucket)
        blob = bucket.get_blob(input.path)
        for line in blob.open('rb'):
            yield GCSPathDataExtractorBlockOutput(
                result=GCSFileData(
                metadata=self._get_metadata(blob),
                content=line,
                path=f'{input.bucket}/{input.path}',
                ),
            )
