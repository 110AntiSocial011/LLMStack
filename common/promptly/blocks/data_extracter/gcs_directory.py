# AUTOGENERATED
import re
from typing import Dict
from typing import Generator
from typing import Generic
from typing import Optional

from google.cloud import storage

from common.promptly.core.base import BaseConfiguration
from common.promptly.core.base import BaseConfigurationType
from common.promptly.core.base import BaseInput
from common.promptly.core.base import BaseInputType
from common.promptly.core.base import BaseOutput
from common.promptly.core.base import BaseOutputType
from common.promptly.core.base import BaseProcessor
from common.promptly.core.base import Schema


class GCSPathDataExtractorBlockInput(BaseInput):
    """ GCS directory path to extract data from"""
    path: str
    bucket: str
    regex: Optional[str] = None


class GCSResponseMetadata(Schema):
    id: str
    generation: str
    time_created: Optional[str] = None
    updated: Optional[str] = None


class GCSFileData(Schema):
    metadata: GCSResponseMetadata
    content: bytes
    path: str


class GCSPathDataExtractorBlockOutput(BaseOutput):
    result: GCSFileData


class GCSPathDataExtractorBlockConfiguration(BaseConfiguration):
    project: Optional[str] = None
    credentials: Optional[Dict] = None


class GCSPathDataExtractorBlock(BaseProcessor[GCSPathDataExtractorBlockInput, GCSPathDataExtractorBlockOutput, GCSPathDataExtractorBlockConfiguration], Generic[BaseInputType, BaseOutputType, BaseConfigurationType]):
    def __init__(self, configuration: dict):
        super().__init__(configuration)
        if configuration.get('credentials'):
            storage.Client.from_service_account_info(
                configuration['credentials'],
            )
        else:
            self._gcs_client = storage.Client(project=configuration['project'])

    def _get_metadata(self, gcs_object):
        return GCSResponseMetadata(
            id=gcs_object.id,
            generation=gcs_object.generation,
            time_created=gcs_object.time_created.isoformat(),
            updated=gcs_object.updated.isoformat(),
        )

    def _get_file_content(self, gcs_object):
        content = gcs_object.download_as_bytes()
        if type(content) == bytes:
            return content
        elif type(content) == str:
            return content.encode('utf-8')
        else:
            raise Exception('Unknown content type')

    def _process_iter(self, input: GCSPathDataExtractorBlockInput, configuration: GCSPathDataExtractorBlockConfiguration) -> Generator[GCSPathDataExtractorBlockOutput, None, None]:
        bucket = self._gcs_client.get_bucket(input.bucket)
        regex = re.compile(input.regex) if input.regex else None

        for blob in bucket.list_blobs(prefix=input.path):
            if not regex or regex.match(blob.name):
                blob.reload()
                yield GCSPathDataExtractorBlockOutput(
                    result=GCSFileData(
                    metadata=self._get_metadata(blob),
                    content=self._get_file_content(blob),
                    path=f'gs://{input.bucket}/{blob.name}',
                    ),
                )

    def _process(self, input: GCSPathDataExtractorBlockInput, configuration: GCSPathDataExtractorBlockConfiguration) -> GCSPathDataExtractorBlockOutput:
        raise NotImplementedError(
            'This block only supports process_iter method',
        )
